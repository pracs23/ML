CLASSIFICATION:


sklearn.naive_bayes.GaussianNB:
https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html

Accuracy is defined as the number of test points that are classified correctly divided by the total number of test points.
  clf.score(features_test, labels_test)
  
  posterior probabilities by normalizing.
  
  Reference: https://github.com/udacity/ud120-projects
  
  Installation:
  We will use pip to install some packages. First get and install pip from here. Using pip, install a bunch of python packages:

go to your terminal line (don’t open python, just the command prompt)
install sklearn: pip install scikit-learn
-- for your reference, here’s the sklearn installation instructions
install natural language toolkit: pip install nltk
Get the Intro to Machine Learning source code. You will need git to clone the repository: git clone https://github.com/udacity/ud120-projects.git


Practice: https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/

SVM:
https://scikit-learn.org/stable/modules/svm.html

Supervised Machine learning algorithms:
1. Naive Bayes
2. SVM
3. Decision Trees


https://scikit-learn.org/stable/modules/classes.html

More ML algorithms:

* k nearest neighbors [The KNN algorithm assumes that similar things exist in close proximity. In other words, similar things are near to each other.]
(https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761))

* random forest: Random forest is a Supervised Machine Learning Algorithm that is used widely in Classification and Regression problems. It builds decision trees on different samples and takes their majority vote for classification and average in case of regression.
(https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/)

* adaboost (sometimes also called boosted decision tree): AdaBoost also called Adaptive Boosting is a technique in Machine Learning used as an Ensemble Method. The most common algorithm used with AdaBoost is decision trees with one level that means with Decision trees with only 1 split. These trees are also called Decision Stumps.
(https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/)

There are mainly 3 types of boosting algorithms:

AdaBoost algorithm
Gradient descent algorithm
Xtreme gradient descent algorithm



REGRESSION:

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn-linear-model-linearregression
sklearn.linear_model.LinearRegression


